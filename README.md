Visual SLAM for Robotics Perception
This repository contains a Python implementation of Monocular Visual SLAM.

Overview
The code is structured into several Jupyter Notebooks that guide you through building and understanding a Visual SLAM pipeline step-by-step.

Notebooks
SLAM_pipeline_step_by_step.ipynb
A complete walkthrough of the monocular SLAM pipeline using the KITTI dataset.

mapping.ipynb
Focuses on the mapping component of the SLAM pipeline.

bundle_adjustment.ipynb
Demonstrates the use of g2o and the concept of bundle adjustment.

Dataset
The pipeline uses the KITTI dataset (grayscale, ~22 GB).
You can download it from the official KITTI Vision Benchmark Suite.